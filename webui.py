#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
SenseVoice Web UI
æä¾›å›¾å½¢ç•Œé¢è¿›è¡Œè¯­éŸ³è¯†åˆ«
"""

import os
import gradio as gr
from funasr import AutoModel


# å…¨å±€æ¨¡å‹å˜é‡
model = None
model_name = "small"


def load_model(model_dir=None, selected_model="small"):
    """åŠ è½½æ¨¡å‹"""
    global model, model_name
    
    model_map = {
        "small": "iic/SenseVoiceSmall",
        "medium": "iic/SenseVoiceMedium"
    }
    
    model_name = selected_model
    model_id = model_map[selected_model]
    
    try:
        if model_dir and os.path.exists(model_dir):
            model = AutoModel(
                model=model_dir,
                device="cpu",
                vad_model="fsmn-vad",
                punc_model="ct-punc",
            )
        else:
            model = AutoModel(
                model=model_id,
                device="cpu",
                vad_model="fsmn-vad",
                punc_model="ct-punc",
            )
        return "âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ"
    except Exception as e:
        return f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"


def transcribe(audio_file, model_dir_input):
    """è½¬å½•éŸ³é¢‘"""
    global model
    
    if model is None:
        return "é”™è¯¯: è¯·å…ˆåŠ è½½æ¨¡å‹"
    
    if audio_file is None:
        return "é”™è¯¯: è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶æˆ–å½•åˆ¶éŸ³é¢‘"
    
    try:
        result = model.generate(input=audio_file)
        
        if result and len(result) > 0:
            text = result[0].get("text", "")
            return text
        else:
            return "è¯†åˆ«å¤±è´¥ï¼Œæœªè¿”å›ç»“æœ"
    except Exception as e:
        return f"è¯†åˆ«é”™è¯¯: {str(e)}"


def transcribe_realtime(audio, auto_submit):
    """å®æ—¶è½¬å½•éŸ³é¢‘ï¼ˆå½•éŸ³åè‡ªåŠ¨è¯†åˆ«ï¼‰"""
    global model
    
    if model is None:
        return "é”™è¯¯: è¯·å…ˆåŠ è½½æ¨¡å‹", None
    
    if audio is None:
        return "ç­‰å¾…å½•éŸ³...", None
    
    try:
        import tempfile
        import numpy as np
        import soundfile as sf
        
        # å¤„ç†ä¸åŒçš„éŸ³é¢‘è¾“å…¥æ ¼å¼
        if isinstance(audio, tuple):
            # Gradio Audio è¿”å›æ ¼å¼: (sample_rate, audio_data)
            sample_rate, audio_data = audio
            # è½¬æ¢ä¸º numpy æ•°ç»„
            if isinstance(audio_data, list):
                audio_data = np.array(audio_data, dtype=np.float32)
            elif not isinstance(audio_data, np.ndarray):
                audio_data = np.array(audio_data, dtype=np.float32)
            
            # å¦‚æœæ˜¯å•å£°é“ï¼Œç¡®ä¿æ˜¯ 1D æ•°ç»„
            if len(audio_data.shape) > 1 and audio_data.shape[0] == 1:
                audio_data = audio_data[0]
            
            # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
            tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
            tmp_file.close()
            sf.write(tmp_file.name, audio_data, sample_rate)
            audio_path = tmp_file.name
        elif isinstance(audio, str):
            # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„
            audio_path = audio
        elif isinstance(audio, dict):
            # Gradio å¯èƒ½è¿”å›å­—å…¸æ ¼å¼
            audio_path = audio.get("name") or audio.get("path")
            if not audio_path:
                return "é”™è¯¯: æ— æ³•è·å–éŸ³é¢‘æ–‡ä»¶è·¯å¾„", None
        else:
            return f"é”™è¯¯: ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {type(audio)}", None
        
        # æ‰§è¡Œè¯†åˆ«
        result = model.generate(input=audio_path)
        
        if result and len(result) > 0:
            text = result[0].get("text", "")
            return text, audio_path
        else:
            return "è¯†åˆ«å¤±è´¥ï¼Œæœªè¿”å›ç»“æœ", audio_path
    except Exception as e:
        import traceback
        error_msg = f"è¯†åˆ«é”™è¯¯: {str(e)}\n{traceback.format_exc()}"
        return error_msg, None


def create_interface():
    """åˆ›å»º Gradio ç•Œé¢"""
    with gr.Blocks(title="SenseVoice è¯­éŸ³è¯†åˆ«") as demo:
        gr.Markdown("# SenseVoice è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ")
        gr.Markdown("æ”¯æŒå®æ—¶å½•éŸ³è¯†åˆ«å’ŒéŸ³é¢‘æ–‡ä»¶ä¸Šä¼ è¯†åˆ«")
        
        with gr.Row():
            with gr.Column():
                model_selector = gr.Radio(
                    choices=["small", "medium"],
                    value="small",
                    label="é€‰æ‹©æ¨¡å‹"
                )
                model_dir_input = gr.Textbox(
                    label="æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰",
                    placeholder="ä¾‹å¦‚: ./models/iic/SenseVoiceSmall",
                    value="./models/iic/SenseVoiceSmall"
                )
                load_btn = gr.Button("åŠ è½½æ¨¡å‹", variant="primary")
                model_status = gr.Textbox(label="æ¨¡å‹çŠ¶æ€", interactive=False)
        
        with gr.Tabs():
            with gr.TabItem("ğŸ¤ å®æ—¶å½•éŸ³è¯†åˆ«"):
                gr.Markdown("### ç‚¹å‡»ä¸‹æ–¹å½•éŸ³æŒ‰é’®ï¼Œå¼€å§‹è¯´è¯ï¼Œå½•éŸ³ç»“æŸåè‡ªåŠ¨è¯†åˆ«")
                with gr.Row():
                    with gr.Column():
                        realtime_audio = gr.Audio(
                            label="å®æ—¶å½•éŸ³",
                            type="numpy",
                            sources=["microphone"],
                            format="wav"
                        )
                        auto_submit = gr.Checkbox(
                            label="å½•éŸ³åè‡ªåŠ¨è¯†åˆ«",
                            value=True
                        )
                        realtime_transcribe_btn = gr.Button("å¼€å§‹è¯†åˆ«", variant="primary")
                    with gr.Column():
                        realtime_output = gr.Textbox(
                            label="è¯†åˆ«ç»“æœ",
                            lines=10,
                            interactive=False
                        )
                        realtime_audio_playback = gr.Audio(
                            label="å½•éŸ³å›æ”¾",
                            type="filepath",
                            interactive=False
                        )
            
            with gr.TabItem("ğŸ“ ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"):
                gr.Markdown("### ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè¯†åˆ«")
                with gr.Row():
                    with gr.Column():
                        audio_input = gr.Audio(
                            label="ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶",
                            type="filepath",
                            sources=["upload"]
                        )
                        transcribe_btn = gr.Button("å¼€å§‹è¯†åˆ«", variant="primary")
                    with gr.Column():
                        output_text = gr.Textbox(
                            label="è¯†åˆ«ç»“æœ",
                            lines=10,
                            interactive=False
                        )
        
        # ç»‘å®šäº‹ä»¶
        load_btn.click(
            fn=load_model,
            inputs=[model_dir_input, model_selector],
            outputs=model_status
        )
        
        transcribe_btn.click(
            fn=transcribe,
            inputs=[audio_input, model_dir_input],
            outputs=output_text
        )
        
        # å®æ—¶å½•éŸ³è¯†åˆ«
        realtime_transcribe_btn.click(
            fn=transcribe_realtime,
            inputs=[realtime_audio, auto_submit],
            outputs=[realtime_output, realtime_audio_playback]
        )
        
        # å¦‚æœå¯ç”¨è‡ªåŠ¨è¯†åˆ«ï¼Œå½•éŸ³ç»“æŸåè‡ªåŠ¨è§¦å‘
        realtime_audio.change(
            fn=transcribe_realtime,
            inputs=[realtime_audio, auto_submit],
            outputs=[realtime_output, realtime_audio_playback]
        )
        
        # è‡ªåŠ¨åŠ è½½é»˜è®¤æ¨¡å‹
        demo.load(
            fn=load_model,
            inputs=[model_dir_input, model_selector],
            outputs=model_status
        )
    
    return demo


def main():
    """ä¸»å‡½æ•°"""
    print("å¯åŠ¨ SenseVoice Web UI...")
    print("è®¿é—®åœ°å€: http://localhost:7860")
    
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )


if __name__ == "__main__":
    main()

